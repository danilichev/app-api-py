{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import InceptionResnetV1\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import models, transforms\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_indx = 0\n",
    "device = torch.device(gpu_indx if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "workers = 0 if os.name == 'nt' else 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "dataset_path = '../temp/utkcropped'\n",
    "epochs_num = 10\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_is_image(file_name):\n",
    "    return file_name.endswith('.jpg')\n",
    "\n",
    "def get_age_from_file_name(file_name):\n",
    "    return int(file_name.split('_')[0])\n",
    "\n",
    "def get_images(directory, max_age=100):\n",
    "    def is_valid(image):\n",
    "        return check_is_image(image) and get_age_from_file_name(image) <= max_age\n",
    "        \n",
    "    images = [image for image in os.listdir(directory) if is_valid(image)]\n",
    "    return images\n",
    "\n",
    "def get_ages(images):\n",
    "    all_ages = [get_age_from_file_name(file_name) for file_name in images]\n",
    "    unique_ages = set(all_ages)\n",
    "    return sorted(list(unique_ages))\n",
    "\n",
    "def reduce_dataset(images, max_age=100, max_images_per_age=100):\n",
    "    ages = get_ages(images)\n",
    "    images_per_age = {age: 0 for age in ages}\n",
    "    reduced_images = []\n",
    "    \n",
    "    for image in images:\n",
    "        age = get_age_from_file_name(image)\n",
    "        if age <= max_age and images_per_age[age] < max_images_per_age:\n",
    "            images_per_age[age] += 1\n",
    "            reduced_images.append(image)\n",
    "            \n",
    "    return reduced_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23622\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "max_age = 90\n",
    "images = get_images(dataset_path, max_age)\n",
    "print(len(images))\n",
    "age_groups = [str(age) for age in get_ages(images)]\n",
    "\n",
    "print(len(age_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UTKFaceDataset(Dataset):\n",
    "    def __init__(self, directory, max_age, transform=None):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.images = get_images(directory, max_age)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.directory, self.images[idx])\n",
    "        image = Image.open(img_name)\n",
    "        age = get_age_from_file_name(self.images[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_info(dataset, name):\n",
    "    ages = []\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        _, age = dataset[i]\n",
    "        ages.append(age)\n",
    "\n",
    "    plt.title(f'{name} Ages Distribution')\n",
    "    plt.xlabel('Person Age')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.hist(ages)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transfrom = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    transforms.RandomRotation(10),\n",
    "])\n",
    "\n",
    "dataset = UTKFaceDataset(dataset_path, max_age=max_age, transform=transfrom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_info(dataset, 'UTKFace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_partition = 0.8\n",
    "valid_partition = 0.1\n",
    "test_partition = 0.1\n",
    "\n",
    "train_examples_num = int(len(dataset) * train_partition)\n",
    "valid_examples_num = int(len(dataset) * valid_partition)\n",
    "test_examples_num = len(dataset) - train_examples_num - valid_examples_num\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = random_split(\n",
    "    dataset,\n",
    "    [train_examples_num, valid_examples_num, test_examples_num],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of training examples: {len(train_dataset)}')\n",
    "print(f'Number of validation examples: {len(valid_dataset)}')\n",
    "print(f'Number of testing examples: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, columns = 2, 2\n",
    "\n",
    "def GetRandom(): return np.random.randint(0, len(train_dataset)-1)\n",
    "\n",
    "randomIndex = [GetRandom() for _ in range(rows * columns)]\n",
    "\n",
    "for i in range(rows * columns):\n",
    "    x, y = train_dataset[randomIndex[i]]\n",
    "    age_group_index = int(y)\n",
    "    age_group = age_groups[age_group_index]\n",
    "\n",
    "    plt.subplot(rows, columns, i + 1)\n",
    "    plt.title(f'Age: {age_group}')\n",
    "    plt.imshow(x.numpy()[0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "model.fc = nn.Linear(512, len(age_groups) + 2)\n",
    "model = nn.Sequential(model, torch.nn.Sigmoid()).to(device)\n",
    "\n",
    "model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, loss_fn, loss_logger):\n",
    "    model.train()\n",
    "\n",
    "    for i, (x, y) in enumerate(tqdm(loader, leave=False, desc=\"Training\")):\n",
    "        forward_pass = model(x.to(device))\n",
    "        loss = loss_fn(forward_pass, y.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_logger.append(loss.item())\n",
    "        \n",
    "    return model, optimizer, loss_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    epoch_accuracy = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(tqdm(loader, leave=False, desc=\"Evaluating\")):\n",
    "            forward_pass = model(x.to(device))\n",
    "            epoch_accuracy += (forward_pass.argmax(1) == y.to(device)).sum().item()\n",
    "\n",
    "    return epoch_accuracy / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_logger = []\n",
    "train_acc_logger = []\n",
    "valid_acc_logger = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(epochs_num, desc=\"Epochs\"):\n",
    "    model, optimizer, train_loss_logger = train(model, train_loader, optimizer, loss_fn, train_loss_logger)\n",
    "    \n",
    "    train_accuracy = evaluate(model, train_loader)\n",
    "    train_acc_logger.append(train_accuracy)\n",
    "    \n",
    "    valid_accuracy = evaluate(model, valid_loader)\n",
    "    valid_acc_logger.append(valid_accuracy)\n",
    "    clear_output(wait=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
